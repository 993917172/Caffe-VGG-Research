{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caffe Shrinking Tool(Coarse-Prune) For VGG-DictNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Caffe Directory Setting\n",
    "caffe_root = '../'\n",
    "\n",
    "import sys \n",
    "import os\n",
    "import numpy as np\n",
    "import os.path as osp\n",
    "import codecs\n",
    "\n",
    "# Import Caffe Python Library\n",
    "sys.path.append(caffe_root + 'python')\n",
    "import caffe \n",
    "\n",
    "# Import Custom Library\n",
    "sys.path.append(\"utils\")\n",
    "sys.path.append(\"utils/layers\")\n",
    "sys.path.append(\"utils/nets\")\n",
    "sys.path.append(\"utils/net_shrink\")\n",
    "\n",
    "from multilabel_datalayers import *\n",
    "from pynet import *\n",
    "import tools\n",
    "from shrink_tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model Setting\n",
    "output_num = 88172\n",
    "working_folder = \"vgg_dictnet_shrink_%d_n/\" % output_classes\n",
    "\n",
    "# Training & Testing Path\n",
    "vgg_data_path = \"../vgg_data/\"\n",
    "train_file = vgg_data_path + \"train.txt\"\n",
    "val_file = vgg_data_path + \"val.txt\"\n",
    "\n",
    "# Hyper-Parameters\n",
    "policy = \"keep\"\n",
    "batch_sz = 256\n",
    "train_epoches = 1\n",
    "retrain = True\n",
    "step_size = train_iteration // 1\n",
    "input_fc = [4096, 4096, output_num]\n",
    "output_fc = [3821, 3821, output_num]\n",
    "\n",
    "# Caffe Mode\n",
    "caffe.set_mode_gpu()\n",
    "caffe.set_device(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get VGG-dictnet Data & Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG Data found!\n"
     ]
    }
   ],
   "source": [
    "# Get VGG-DictNet Data\n",
    "if os.path.isdir(caffe_root + \"vgg_data\"):\n",
    "    print 'VGG Data found!'\n",
    "else:\n",
    "    print 'Downloading VGG Data (about 10G)'\n",
    "    !wget http://www.robots.ox.ac.uk/~vgg/data/text/mjsynth.tar.gz -0 {caffe_root}/vgg_data.tar.gz\n",
    "    !tar xvf {caffe_root}/vgg_data.tar.gz -C {caffe_root}/vgg_data\n",
    "    \n",
    "# Get VGG-DictNet Model\n",
    "if os.path.isfile(caffe_root + 'models/vgg_dictnet_mtoc/dictnet_vgg_mtoc.caffemodel'):\n",
    "    print 'VGG Models found.'\n",
    "else:\n",
    "    print 'Downloading pre-trained VGG models...'\n",
    "    !wget https://www.dropbox.com/s/i4tu1rq7r021xkr/vgg_dictnet_mtoc.tar.gz\n",
    "    ! mkdir  {caffe_root}models/vgg_dictnet_mtoc\n",
    "    !tar xvf vgg_dictnet_mtoc.tar.gz -C {caffe_root}models/vgg_dictnet_mtoc\n",
    "    ! rm vgg_dictnet_mtoc_10000.tar.gz\n",
    "    \n",
    "model_load = osp.join(caffe_root + 'models/vgg_dictnet_mtoc/dictnet_vgg_mtoc.caffemodel')\n",
    "data_list = \"../vgg_data/lexicon.txt\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reTrainModel(solver, train_iteration, threshold):\n",
    "    \n",
    "    print \"Train Iteration: %d\" % train_iteration\n",
    "    loss = []\n",
    "    \n",
    "    for i in range(train_iteration // 200+1):\n",
    "        solver.step(200)\n",
    "        loss += solver.net.blobs['loss'].data\n",
    "        if len(loss) == 6:\n",
    "            loss.pop(0)\n",
    "        elif np.mean(loss) < threshold:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Start Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: Syntax error: \"(\" unexpected\n",
      "vgg_dictnet_shrink_10000_n/prototxt/4000/solver_fc1_4000_fc2_4000.prototxt\n",
      "vgg_dictnet_shrink_10000_n/prototxt/4000/trainnet_fc1_4000_fc2_4000.prototxt\n",
      "vgg_dictnet_shrink_10000_n/prototxt/4000/valnet_fc1_4000_fc2_4000.prototxt\n",
      "vgg_dictnet_shrink_10000_n/prototxt/4000/deploynet_fc1_4000_fc2_4000.prototxt\n",
      "Train Iteration: 3233\n",
      "New Model Name: snap_fc1_4000_fc2_0.caffemodel\n",
      "---------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/numpy/core/_methods.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# If loss less than 0.3, than break the for-loop to save model\n",
    "loss_threshold = 0.3\n",
    "\n",
    "train_iteration =len(codecs.open(train_file, 'r', 'utf8').readlines()) * train_epoches / batch_sz\n",
    "\n",
    "if osp.isdir(osp.join(working_folder, \"models\")) is False:\n",
    "    os.makedirs(osp.join(working_folder, \"models\"))\n",
    "    \n",
    "!cp {model_load} {osp.join(working_folder, \"models\", \"snap_fc1_0_fc2_0.caffemodel\")}\n",
    "    \n",
    "pro = Create_prototxt(working_folder, policy, batch_sz, data_list, step_size, train_file, val_file)\n",
    "\n",
    "solver = shrink_fc(pro, working_folder, input_fc, output_fc, step)\n",
    "    \n",
    "    \n",
    "# Start Retrain\n",
    "if retrain is True:\n",
    "    solver = reTrainModel(solver_d, train_iteration, loss_threshold)\n",
    "\n",
    "solver.net.save(osp.join(working_folder,\"models\", \"new.caffemodel\"))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "description": "Multilabel classification on PASCAL VOC using a Python data layer.",
  "example_name": "Multilabel Classification with Python Data Layer",
  "include_in_docs": true,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "priority": 5
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
